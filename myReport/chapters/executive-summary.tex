% Executive summary (1 page) — A 1-page summary of the project, to include the main research idea or hypothesis, the main features of the experimental design, a summary of the main result(s), and a conclusion.
\chapter{Executive Summary}

\section{Motivation and Objective}

Functional Status Information (FSI), descriptions of how well patients carry out everyday tasks, remains hidden in the free text of electronic health records. Revealing it can sharpen clinical insight and make care more patient-centred. This project therefore asked whether natural-language processing (NLP) can detect and classify FSI sentences in MIMIC-IV discharge summaries, assigning each sentence to one of four International Classification of Functioning (ICF) domains, which are Mobility, Self-Care and Domestic Life, Interpersonal Interactions and Relationships (IPIR) and Communication and Cognition. \medskip

\section{Experimental Design and Approach}

Because no labelled corpus existed, the study pursued two complementary strategies. In the supervised part, the team created a silver-standard dataset by manually annotating sentences according to ICF guidelines and then trained three contrasting models. A CNN–RNN hybrid network used FastText embeddings, convolutional layers for local patterns, and gated recurrent layers for context. A lighter feed-forward network relied on mean-pooled embeddings and served as a baseline, while a Random Forest combined TF-IDF features with FastText vectors to offer an interpretable alternative. In the unsupervised part, Latent Dirichlet Allocation extracted topic mixtures from bag-of-words representations, K-Means clustering grouped sentences by contextual embeddings from ClinicalBERT and BioBERT, and a rule-based variant seeded clusters with high-confidence ICF keywords before propagating labels to similar sentences. \medskip

\section{Main Results}
The CNN-RNN hybrid network achieved the best supervised performance, recording a micro-average F1 of 0.74. Mobility sentences were retrieved with the highest precision and recall—reflecting their prevalence in the corpus—while Communication and Cognition, though sparse, were identified reasonably well. IPIR proved toughest for both annotators and models, owing to subtle phrasing and conceptual overlap with other domains. Among unsupervised techniques, K-Means over ClinicalBERT embeddings produced the clearest clusters, again separating Mobility and Communication effectively but merging many IPIR and Self-Care sentences. \medskip

\section{Conclusion and Challenges}
One of the most critical issues was the quality and consistency of manual annotations, particularly across the four ICF categories. Given that annotations were performed by non-experts, variation in interpretation led to label noise that affected the reliability of supervised learning models. Additionally, there was a pronounced class imbalance in the dataset, with Mobility-related sentences overrepresented compared to under-represented domains such as Communication and Cognition. This skew introduced performance bias and limited the models’ ability to generalise across all functional domains. A third challenge lay in the inherent ambiguity of language used to describe functional status; relevant information was often context-dependent or expressed in subtle, implicit ways that were difficult for both human annotators and models to capture. \medskip

These limitations underscore the need for a more robust and scalable foundation for future work. In particular, the development of a gold-standard dataset, constructed in collaboration with domain experts, should be prioritised. Such a resource would significantly reduce non-expert label ambiguity and allow for more accurate training, evaluation, and benchmarking of FSI extraction models. \medskip

To address data imbalance and linguistic ambiguity, future work may focus on the exploration of strategies such as data augmentation, semi-supervised learning, and the development of domain-adapted language models suitable for medical use. Techniques like active learning could also improve annotation efficiency and are addressed in greater detail in the discussion and conclusions chapter.\medskip

Despite these challenges, this project demonstrates the feasibility of extracting sparse but clinically valuable FSI from unstructured EHR text. It provides a proof of concept for integrating functional information into computational pipelines and lays the groundwork for more comprehensive, patient-centred data extraction efforts within electronic health record systems.