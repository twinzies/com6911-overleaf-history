% Executive summary (1 page) — A 1-page summary of the project, to include the main research idea or hypothesis, the main features of the experimental design, a summary of the main result(s), and a conclusion.
\chapter{Executive Summary}
\section{Needle in the Haystack: Investigating Sparse Functional Status Information with NLP}
\subsection{Motivation and Objective}

Functional Status Information (FSI)—which captures a patient's ability to perform daily activities—offers significant potential to enhance clinician insight and support patient-centred care. However, FSI is often embedded within unstructured Electronic Health Record (EHR) notes, making it challenging to systematically identify and extract. This project addresses that challenge by developing and evaluating the use of Natural Language Processing (NLP) models to detect and classify FSI within clinical free-text notes derived from discharge summaries in the MIMIC-IV dataset. The primary objective is to map sentences from the dataset to four key categories based on the International Classification of Functioning (ICF): Mobility, Self-Care and Domestic Life, Interpersonal Interactions and Relationships (IPIR), and Communication and Cognition.

\subsection{Experimental Design and Approach}
Due to the absence of publicly available labelled data for Functional Status Information (FSI) classification, the project adopted two complementary methodological strategies: supervised and unsupervised learning. \medskip

In the supervised learning approach, a silver-standard dataset was manually annotated by the project team, following official ICF guidelines to ensure conceptual alignment with established functional domains. Three models were developed and evaluated for their ability to classify sentences into FSI categories. The first was a CNN-RNN hybrid architecture, which combined pre-trained FastText embeddings with convolutional layers for local pattern extraction and recurrent layers for capturing sequential context. The second was a simpler Feedforward Neural Network (FNN), which operated on mean-pooled FastText embeddings and provided a lower-complexity baseline. The third model was a Random Forest classifier, trained on a hybrid feature set comprising TF-IDF and FastText vectors. Although more interpretable, this model was less capable of capturing the semantic depth and structural nuance of clinical language compared to its neural counterparts. \medskip

The unsupervised learning strategy focused on discovering semantic groupings in the data without the use of annotated labels. Latent Dirichlet Allocation (LDA) was applied to term-frequency-based representations to identify probabilistic topic distributions within the corpus. Additionally, K-Means clustering was used in conjunction with sentence embeddings derived from ClinicalBERT and BioBERT, allowing the grouping of semantically similar sentences based on contextualised representations. A third method involved a hybrid, rule-based approach that leveraged ICF-derived lexicons to assign high-confidence labels to selected sentences, which were then extended through clustering techniques to propagate labels across similar instances. \medskip

\subsection{Main Results}
Amongst the supervised models, a hybrid CNN-RNN achieved the highest performance with a micro-average F1 score of 0.74 - outperforming the fully connected neural network (micro-F1 0.67) and the Random Forest classifier. Sentences pertaining to mobility were identified accurately with a high precision and recall, which may be attributed to a greater abundance of sentences overall for this category in the discharge summaries. The models performed well on sentences related to Communication and Cognition, despite the comparatively limited number of examples in this category.\medskip

Sentences for the IPIR category proved comparatively challenging. It is important to note that due to nuances in its annotation guidelines \cite{InterpersonalGuideline2023}, these were especially complex for manual annotators to identify too. \medskip

The Unsupervised approach with K-Means semantic clustering followed similar trends: it accurately grouped sentences belonging to categories such as mobility and communication, but struggled to isolate the rest. The K-Means clustering with pre-trained Clinical Bert embeddings showed the best performance amongst unsupervised approaches.\medskip

Overall, these findings highlight both the promise and limitations of using NLP techniques for FSI extraction. While high performance was achieved in categories with clearer lexical patterns and more training data, performance can vary substantially across functional domains. This highlights the need for category-specific modelling strategies and improved annotation resources to support more accurate, generalisable and increasingly more nuanced classification.

\subsection{Conclusion and Challenges}
One of the most critical issues was the quality and consistency of manual annotations, particularly across the four ICF categories. Given that annotations were performed by non-experts, variation in interpretation led to label noise that affected the reliability of supervised learning models. Additionally, there was a pronounced class imbalance in the dataset, with Mobility-related sentences overrepresented compared to under-represented domains such as Communication and Cognition. This skew introduced performance bias and limited the models’ ability to generalise across all functional domains. A third challenge lay in the inherent ambiguity of language used to describe functional status; relevant information was often context-dependent or expressed in subtle, implicit ways that were difficult for both human annotators and models to capture.

These limitations underscore the need for a more robust and scalable foundation for future work. In particular, the development of a gold-standard dataset, constructed in collaboration with domain experts, should be prioritised. Such a resource would significantly reduce non-expert label ambiguity and allow for more accurate training, evaluation, and benchmarking of FSI extraction models. \medskip

To address data imbalance and linguistic ambiguity, future work may focus on the exploration of strategies such as data augmentation, semi-supervised learning, and the development of domain-adapted language models suitable for medical use. Techniques like active learning could also improve annotation efficiency and are addressed in greater detail in the discussion and conclusions chapter.\medskip

Despite these challenges, this project demonstrates the feasibility of extracting sparse but clinically valuable FSI from unstructured EHR text. It provides a proof of concept for integrating functional information into computational pipelines and lays the groundwork for more comprehensive, patient-centred data extraction efforts within electronic health record systems.